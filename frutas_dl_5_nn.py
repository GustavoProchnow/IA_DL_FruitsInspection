# -*- coding: utf-8 -*-
"""frutas_dl_5_NN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VKlZNfoyKoIhvOh9iy_aIUmyavafoom6

**Bibliotecas Utilizadas:**
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x

import os
import tensorflow as tf
import numpy as np
import pandas as pd
from tensorflow.keras import layers, models, preprocessing, applications
from collections import defaultdict
from matplotlib import pyplot as plt
import matplotlib.image as mpimg

"""**Conectando o Colab ao meu Drive para poder acessar as Imagens e Pastas:**"""

from google.colab import drive
drive.mount('/content/drive')

"""**Nessa parte é definido os diretórios em que a rede irá acessar para:**

  - Fazer o treinamento;
  - Salvar o modelo treinado;
  - Usar para o teste manual das imagens separadas;


  **Em em seguida:**
  
  - São definidos lotes pra processamento e treinamentos da imagens (Batch Size);
  - E também é feito o redimensionamento das imagens para 244 x 244 pixels;
"""

SEED = None

BASE_DATASET_DIR = 'drive/My Drive/Dataset_frutas/train/'
MODEL_PATH='/content/drive/My Drive/Dataset_frutas/modelos_treinados/modelo10'
TEST_DIR = 'drive/My Drive/Dataset_frutas/test/'

DATASET_DIR = BASE_DATASET_DIR

BATCH_SIZE = 48
INPUT_SIZE = (244, 244)

"""**Nessa parte é utilizado o Keras pra separar as imagens de treinamento das imagens de validação, onde:**

- 80% - treino
- 20% - validação dos resultados
"""

data_generator = preprocessing.image.ImageDataGenerator(
    validation_split=0.2,
    rescale=(1/255)
)

all_images = data_generator.flow_from_directory(
    DATASET_DIR, 
    target_size=INPUT_SIZE,
    batch_size=BATCH_SIZE,
    #color_mode="grayscale",
    seed=SEED
)

all_images_u = data_generator.flow_from_directory(
    DATASET_DIR, 
    target_size=INPUT_SIZE,
    batch_size=1,
    #color_mode="grayscale",
    seed=SEED
)


train_images = data_generator.flow_from_directory(
    DATASET_DIR, 
    target_size=INPUT_SIZE,
    batch_size=BATCH_SIZE,
    #color_mode="grayscale",
    seed=SEED,
    subset='training'
)

validation_images = data_generator.flow_from_directory(
    DATASET_DIR, 
    target_size=INPUT_SIZE,
    batch_size=BATCH_SIZE,
    #color_mode="grayscale",
    seed=SEED,
    subset='validation'
)

"""Aqui é criado o modelo de treinamento usando a arquitetura **VGG16** a partir da estrutura da imagem definida **(244 x 244 pixels em escala RGB)**

- É utilizado também a estrutura do imagenet para fazer o treinamento e mais uma camada de 256 neurônios;

- Após esse processo temos a saída das predições que pode ser em 6 neurônios, represetando assim as nossas 6 possibilidades de resultados (bananas boas e ruins, laranjas boas e ruins e maçã boas e ruins);
"""

a,b = INPUT_SIZE
INPUT_SHAPE = (a,b,3)
# base_model = applications.Xception(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)
base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)

##### Usa esse modelo pra fazer um novo treinamento #####
dropout_rate = 0.5
def create_model2():
    X_inputs = layers.Input(INPUT_SHAPE)

    X = base_model(X_inputs, training=False)

    X = layers.Flatten()(X)
  
    X = layers.Dense(256, activation='relu')(X)
    X = layers.Dropout(dropout_rate)(X)

    predictions = layers.Dense(6, activation='softmax')(X)
  
    model = models.Model(inputs=X_inputs, outputs=predictions)

    return model

"""**Nesse momnto é compilado o modelo criado acima antes de passar pelo treinamento da rede neural:**

- Nessa parte podemos observar as camadas e parâmetros que serão utilizados para treinar a rede neural;
"""

# opt = tf.keras.optimizers.Adam(lr=.0001)
opt = tf.keras.optimizers.Adam()
# opt = tf.keras.optimizers.SGD(lr=0.01)

# loss = tf.keras.losses.SparseCategoricalCrossentropy()
loss = tf.keras.losses.CategoricalCrossentropy()
metrics = ['accuracy']


#reload model = True - carrega o modelo já existente na pasta e pode ser retreinado    /    #reload_model = False - cria um novo treino
reload_model = False
if reload_model and os.path.exists(MODEL_PATH):
    print('Loading Model from file')
    model = models.load_model(MODEL_PATH)
else:                                       
    print('Creating model from scratch')
    model = create_model2()

for layer in base_model.layers:
    layer.trainable = False

model.compile(optimizer=opt, loss=loss, metrics=metrics)

model.summary()

os.path.exists(MODEL_PATH)

"""Agora nessa etapa é feito o treinamento da rede neural, é utilizado:

- 70 épocas para treinamento da rede;
- 12 de passoas de validação;
- 12 de passos por época;

Ao final é salvo o modelo treinado no diretório de salvamento escolhido no começo do código.

"""

# with tf.device('/device:GPU:0'):
#with tf.device(device_name):
history = model.fit(
    train_images, 
    validation_data=validation_images,
    validation_steps=12,
    steps_per_epoch=12,
    epochs=70,
  )

model.save(MODEL_PATH)

"""Utilizando os Parâmetros acima, a rede conseguiu gerar bons resultados de treinamento, onde:

**- Imagens de Treino:**

    - Erro / loss: 0.0468
    - Acurácia / accuracy: 0.9844

**- Imagens de Validação:**

    - Erro / val_loss: 0.1217
    - Acurácia / val_accuracy: 0.9618
"""

model = tf.keras.models.load_model(MODEL_PATH)

"""**Ao final do treinamento é plotado o Gráfico, nele podemos observar como a rede se comportou durante o treinamento:**

- é interessante observar que a curva do erro do gráfico conseguiu convergir bem em relação as duas vertentes, que no caso são as imagens utilizada para o treino, e as imagens de validação do treino;

- o mesmo acontece para a curva de acurácia do gráfico, ambas as vertentes conseguiram convergir bem, no caso acurácia em relação as imagens de treino e acurácia em relação as imagens de validação;
"""

fig, axs = plt.subplots(2, figsize=(24,9))

hist = history.history
axs[0].plot(hist['loss'], label='loss')
axs[0].plot(hist['val_loss'], label='val_loss')

axs[0].legend();

axs[1].plot(hist['accuracy'], label='accuracy')
axs[1].plot(hist['val_accuracy'], label='val_accuracy')

axs[1].legend();

"""**Após o treinamento da rede, é feito a predição das imagens separadas para teste da rede neural artificial:**

- Nesse primeiro passo é criado um dicionário com as opções de labels, onde labels = resultado das imagens;

- Então cada imagem recebe um número respectivo ao seu resultado, conforme podemos observar abaixo;
"""

labels = {
    "banana_boas": 0,
    "banana_ruins": 1,
    "laranja_boas": 2,
    "laranja_ruins": 3,
    "maca_boas": 4,
    "maca_ruins": 5,
     }

"""**Nessa parte a seguir é onde o código faz a predição de cada imagem do conjunto de treino:**

- primeiro é feita a normalização das imagens conforme o que foi utilizado para treinamento da rede, ou seja, imagens de 244 x 244 pixels;

- depois o código vai iterando imagem por imagem, conforme as labels que fornecemos acima, dessa forma é possível ver os resultados das imagens, bem como a sua predição de resultado;
"""

from pandas.core.dtypes.common import classes

def load_image(path):
  img = preprocessing.image.load_img(path, target_size=INPUT_SHAPE)
  x = preprocessing.image.img_to_array(img)
  x = np.expand_dims(x/255, axis=0)
  images = np.vstack([x])
  return images

data = defaultdict(list)

#i=0
for index, filename in enumerate(all_images.filenames):
  if filename in data['filename']:
    break
  #if i >=300:
    #break
  #i += 1

  filepath = os.path.join(DATASET_DIR, filename)
  image = load_image(filepath)
  pred = model.predict(image)
  klass = np.argmax(pred[0])
  classe = filename.split("/")[0]

  label = labels[classe]
  data['banana_boas'].append(pred[0][0])
  data['banana_ruins'].append(pred[0][1])
  data['laranja_boas'].append(pred[0][2])
  data['laranja_ruins'].append(pred[0][3])
  data['maca_boas'].append(pred[0][4])
  data['maca_ruins'].append(pred[0][5])
  data['label'].append(label)
  data['predict'].append(klass)
  data['filename'].append(filename)
  data['filepath'].append(filepath)
  data['acc'] = int(klass == label)

df = pd.DataFrame(data)
df.head()

"""**Agora, ao final do código é onde podemos testar efetivamente a rede e ver seu comportamento em prever imagens:**

- Primeiro é buscado a imagem no caminho desejado do Drive, em seguida essa imagem é plotada na tela;

- Na imagem plotada é escrito alguns atributos para podemos saber o resultado da inspeção dessa imagem. Os atributos são:

  - **label** = nome da imagem, que também é o resultado que ela deve obter;

  - **pred** = valor de predição, ou seja, o número conforme o resultado da inspeção;

  - abaixo podemos ver as porcentagens em relação a inspeção da imagem e também conforme a ordem das labels, **onde 1.00 = 100% , 0.50 = 50% , 0.25 = 25%**, e assim por diante;

  - e ao final fazemos uma lógica pra escrever o resultado de inspeção da imagem por escrito, como por exemplo: **"Banana Ruim", "Maçã Boa"**, ou caso o sistema não esteja decidido o suficiente, irá escrever **"Inconclusivo"**;
"""

def load_image(path):
  img = preprocessing.image.load_img(path, target_size=INPUT_SHAPE)
  x = preprocessing.image.img_to_array(img)
  x = np.expand_dims(x / 255, axis=0)
  images = np.vstack([x])
  return images

path = '/content/drive/My Drive/Dataset_frutas/test/banana_ruins/banana_nok (7).png'

img = load_image(path)
pred = model.predict(img)
print(pred)

print('----------')

imgplot = mpimg.imread(path)
fig = plt.figure(figsize = (40, 8))
imgplot = plt.imshow(imgplot)

classe = path.split('/')[6]
classe = labels[classe]


if pred[0][0] > 0.5:
  label = "Banana Boa"
elif pred[0][1] > 0.5:
  label = "Banana Ruim"
elif pred[0][2] > 0.5:
  label = "Laranja Boa"
elif pred[0][3] > 0.5:
  label = "Laranja Ruim"
elif pred[0][4] > 0.5:
  label = "Maçã Boa"
elif pred[0][5] > 0.5:
  label = "Maçã Ruim"
else:
  label = "Inconclusivo"

plt.title(f'label = {classe}, pred = {np.argmax(pred[0])} \n [{pred[0][0]:.2f}/{pred[0][1]:.2f}/{pred[0][2]:.2f}/{pred[0][3]:.2f}/{pred[0][4]:.2f}/{pred[0][5]:.2f}] \n Resultado = {label}')
plt.show()